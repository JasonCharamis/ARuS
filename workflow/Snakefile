ximport os
import re
import subprocess
import itertools


#=============================================================== DOWNLOAD DATA AND GENOME =======================================================================#

def download_data(data_url):
    subprocess.run(["wget", "-O", "data.tar.gz", data_url])
    subprocess.run(["gunzip", "data.tar.gz"])
    subprocess.run(["mkdir", "data"])
    subprocess.run(["tar", "-xf", "data.tar", "--strip-components=1", "-C", "./data"])

def rename_data(files):
    for file in files:
        base_name = os.path.basename(file)
        new_name = os.path.join(os.path.dirname(file), base_name.replace('.trim.sub', ''))
        os.rename(file, new_name)

def check_filenames(directory_path, regex_pattern):
    try:
        if not os.path.exists(directory_path) or not os.path.isdir(directory_path):
            print(f"The directory {directory_path} does not exist.")
            return

        pattern = re.compile(regex_pattern)
        matching_filenames = [filename for filename in glob(os.path.join(directory_path, "*.fastq")) if re.search(pattern, filename)]

        if matching_filenames:
            return matching_filenames

    except Exception as e:
        print(f"An error occurred: {e}")

data_url = config["data_url"]
data_dir = "data"

if not os.path.exists(data_dir) and not os.path.isdir(data_dir):
    download_data(data_url)

matching_files = check_filenames(data_dir, "trim")

if matching_files:
    rename_data(files=matching_files)

samples = [str(file) for file in sorted([f[:-8] for f in os.listdir(data_dir) if f.endswith(".fastq")])]
groups = list(set((re.sub(".*/", "", s) for s in samples)))


def all_pairs(x):
    comparisons = {}
    for sample1, sample2 in itertools.combinations(x, 2):
        comparisons[str(sample1 + "_" + sample2)] = str(sample1 + "_vs_" + sample2)
    return list(comparisons.values())

de_subsets = all_pairs(groups)

# Add a new wildcard for the subset
wildcard_constraints:
    de_subset = "|".join(de_subsets)

log2FC_cutoff = config['log2FC_cutoff']

rule download_genome:
    output: genome = "genome.fasta",
            gtf = "genome.gtf"
    params: genome_url=config["genome_url"],
            gtf_url=config["gtf_url"]
    
    shell: """ wget -O 'genome.fasta.gz' {params.genome_url} && gunzip 'genome.fasta.gz' && wget -O 'genome.gtf.gz' {params.gtf_url} && gunzip 'genome.gtf.gz' """


#==================================================================== RULE ALL ============================================================================#

rule all:
    input:
        expand(
            "{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.sorted.xlsx",
	     de_subset=de_subsets,
	     log2FC_cutoff = config['log2FC_cutoff']
            )
    run:
        print("List of Samples:", samples)

#=============================================================== FASTQC AND TRIMMING =======================================================================#

rule fastqc:
    input:
        r1='{sample}_1.fastq.gz',
        r2='{sample}_2.fastq.gz'

    output: "fastqc/{sample}_fastqc/fastqc_report.html"
    conda: "envs/config.yaml"
    threads: 1

    shell:
        """ mkdir -p fastqc && 
	    fastqc {input.r1} -t {threads} && 
            fastqc {input.r2} -t {threads} """


rule download_trimmomatic_adapters:
    output: "TruSeq3-PE.fa"
    shell: """ wget -O TruSeq3-PE.fa 'https://raw.githubusercontent.com/usadellab/Trimmomatic/main/adapters/TruSeq3-PE.fa' """
    

rule trim_reads:
    input:
        adapters='TruSeq3-PE.fa',
        r1='{sample}_1.fastq.gz',
        r2='{sample}_2.fastq.gz',
    output:
        r1_trimmed='{sample}_1.trimmed.fastq.gz',
        r2_trimmed='{sample}_2.trimmed.fastq.gz',
        r1_garbage=temp('{sample}_1.garbage.fastq.gz'),
        r2_garbage=temp('{sample}_2.garbage.fastq.gz')
    conda: "envs/config.yaml"
    threads: config['trimmomatic_threads']
    message: "Adapter-trimming reads"
    shell:
        """ trimmomatic PE -threads {threads} {input.r1} {input.r2} {output.r1_trimmed} {output.r1_garbage} {output.r2_trimmed} {output.r2_garbage} ILLUMINACLIP:{input.adapters}:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:50 """


#==================================================================== MAPPING =============================================================================#

rule build_genome_index:
    output: 'index_chkp'
    conda: "envs/config.yaml"
    threads: config['star_build_threads']
    message: "Building genome index"
    params:
        genome_fasta=config['genome_fasta'],
        gtf=config['gtf']
    shell:
        """ mkdir genome/ && STAR --runThreadN {threads} --runMode genomeGenerate --genomeDir genome/ --genomeFastaFiles {params.genome_fasta} --sjdbGTFfile {params.gtf} --sjdbOverhang 149 && touch index_chkp """


rule mapping:
    input:
        ch='index_chkp',
        r1='{sample}_1.fastq',
        r2='{sample}_2.fastq',
    output: '{sample}.Aligned.sortedByCoord.out.bam'
    conda: "envs/config.yaml"
    message: "Mapping reads to genome and convert to sorted BAM"
    threads: config['star_map_threads']
    shell:
        """ STAR --runThreadN {threads} --readFilesIn {input.r1} {input.r2} --genomeDir genome/ --outSAMtype BAM SortedByCoordinate --outFileNamePrefix {wildcards.sample}. """


#================================================================== COUNT ============================================================================#

rule count:
    input: bams=expand('{sample}.Aligned.sortedByCoord.out.bam', sample=samples)
    output: counts='counts.txt'
    conda: "envs/config.yaml"
    threads: config['featureCounts_threads']
    params: gtf=config['gtf']
    shell:
        """ featureCounts -M -s 0 -T {threads} -p -t exon -g gene_id -a {params.gtf} -o {output.counts} {input.bams} """

rule modify:
    input: counts="counts.txt"
    output: counts_mod="counts.mod.txt"
    shell:
        """ perl ARuS/workflow/scripts/counts_mod.pl > {output.counts_mod} """
        
rule samples_list:
    input: counts_mod="counts.mod.txt"
    output: samples_list="samples.list"
    shell:
        """ perl ARuS/workflow/scripts/counts_to_samples_list.pl {input.counts_mod} | sort -Vk2 > {output.samples_list} """

rule counts_to_tpm:
    input: counts="counts.txt",
           file="samples.list"
    output: counts_mod_tpm="counts.mod.tpm"
    shell: """ perl ARuS/workflow/scripts/counts_to_tpm.pl {input.counts} | sed 's/\\.Aligned\\.sortedByCoord\\.out\\.bam//g' | sed 's/gene://g' | sed 's/results\\///g' > {output.counts_mod_tpm} """

rule pca:
    input: counts_tpm="counts.mod.tpm"
    output: "PCA.svg"
    shell: """ Rscript ARuS/workflow/scripts/pca.R {input.counts_tpm} """
    

#==================================================================== RUN DE ANALYSIS ===================================================================#

rule make_directories:
    input:
        samples_list="samples.list",
        pca="PCA.svg",
        counts="counts.txt"
    output:
        "chkp"

    shell: """ 
    mkdir -p edgeR/01_run_DE_analysis &&
    mkdir -p edgeR/02_analyze_DE &&
    cp counts.mod.txt edgeR/01_run_DE_analysis/ &&
    cp {input.samples_list} edgeR/01_run_DE_analysis/ &&
    touch chkp
    """


rule run_DE_analysis:
    input:
        counts_file="counts.mod.txt",
        samples_list="samples.list",
        chkp='chkp'

    output: 'edgeR/chkp01'

    shell: """ cd edgeR/01_run_DE_analysis &&
               perl ARuS/workflow/scripts/run_DE_analysis.pl --matrix ../../../{input.counts_file} --method edgeR --samples_file ../../{input.samples_list} &&
               cd ../ &&
               touch chkp01 """


rule analyze_DE:
    input: 'edgeR/chkp01'
    output: expand('edgeR/02_analyze_DE/counts.mod.txt.{de_subset}.edgeR.DE_results.P1e-3_C{log2FC_cutoff}.DE.subset', de_subset = de_subsets, log2FC_cutoff = log2FC_cutoff ),
    	    'edgeR/chkp02'
    shell: """ cd edgeR/02_analyze_DE &&
            ln -s ../01_run_DE_analysis/edgeR.*/counts.mod.txt* . &&
            perl ARuS/workflow/scripts/analyze_diff_expr.pl --matrix ../../counts.mod.txt --samples ../01_run_DE_analysis/samples.list -P 1e-3 -C {log2FC_cutoff} &&
            cd ../ &&
            touch chkp02 &&
            rm ../chkp ../{input} ../{output} """


rule rename:
    input:
        subset_file='edgeR/02_analyze_DE/counts.mod.txt.{de_subset}.edgeR.DE_results.P1e-3_C{log2FC_cutoff}.DE.subset'
    output:
        subset_file_renamed='edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.subset'
    shell:
        """ perl ARuS/workflow/scripts/rename.pl {input.subset_file} """


#================================================================== POST DE ANNOTATION =================================================================#

rule annotate_DE:
    input: de_file="edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.subset", gene_info=config['gene_info']
    output: annotated="edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.tsv"
    shell: """ perl ARuS/workflow/scripts/annotate_DE.pl {input.de_file} {input.gene_info} > {output.annotated} """


rule reverse_sort:
    input: unsorted="edgeR/02_analyze_DE/{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.tsv"
    output: sorted="{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.sorted.tsv"
    shell: """ perl ARuS/workflow/scripts/reverse_sort.pl {input.unsorted} > {output.sorted} && mv {output.sorted} ../../ """


rule tsv2xlsx:
    input: tsv="{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.sorted.tsv"
    output: "{de_subset}.P1e-3_C{log2FC_cutoff}.DE.annotated.sorted.xlsx"
    shell: """ python3 scripts/tsv2xlsx.py {input.tsv} """
